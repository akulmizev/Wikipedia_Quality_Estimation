load:
  method: "config"
parameters:
  model: "unigram"
  normalizer: "nfkc"
  pre_tokenizer: [
    "metaspace",
    "bert"
  ]
  decoder: "metaspace"
  trainer: "unigram"
  post_processor: true
  special_tokens: {
    mask_token: "[MASK]",
    bos_token: "[BOS]",
    eos_token: "[EOS]",
    sep_token: "[SEP]",
    pad_token: "[PAD]",
    unk_token: "[UNK]",
    cls_token: "[CLS]"
  }
  unk_token: "[UNK]"
  vocab_size: "auto"
  min_frequency: 2
export: true
push_to_hub: true