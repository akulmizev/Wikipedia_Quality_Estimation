#load_path: "./experiments/test/ha/model"

tokenizer_config:
  model:
    type: "bpe"
  vocab_size: "auto"
  use_sp_backend: true
  sp_kwargs:
    byte_fallback: false
  special_tokens:
#    bos_token: "<s>"
#    eos_token: "</s>"
#    pad_token: "<pad>"
#    unk_token: "<unk>"
    cls_token: "[CLS]"
    sep_token: "[SEP]"
    mask_token: "[MASK]"
    pad_token: "[PAD]"
    bos_token: "[BOS]"
    eos_token: "[EOS]"
    unk_token: "[UNK]"

#merge_with: "meta-llama/Llama-2-7b-hf"

export: false
push_to_hub: false